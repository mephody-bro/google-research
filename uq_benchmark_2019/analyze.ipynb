{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from array_utils import load_npz, write_npz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# path = 'mnist/results/stats_0.npz'\n",
    "# load_npz(path)\n",
    "\n",
    "data = {\"lol\": np.array([10])}\n",
    "\n",
    "write_npz('mnist/results', 'test.npz', data)\n",
    "load_npz('mnist/results/test.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from metrics_lib import compute_accuracies_at_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 50, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats = load_npz('mnist/results/svi/stats_small_28.npz')\n",
    "accuracies, count = compute_accuracies_at_confidences(stats['labels'], stats['probs'], thresholds)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(thresholds, count)\n",
    "plt.subplot(122)\n",
    "plt.plot(thresholds, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ood_name = 'stats_small_28.npz'\n",
    "methods = ['vanilla', 'svi', 'dropout', 'll_svi', 'll_dropout']\n",
    "counts = {}\n",
    "for method in methods:\n",
    "    path = os.path.join('mnist/results/',method, ood_name)\n",
    "    stats = load_npz(path)\n",
    "    _, counts[method] = compute_accuracies_at_confidences(stats['labels'], stats['probs'], thresholds)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for method, count in counts.items():\n",
    "    print(method, count)\n",
    "    plt.plot(thresholds, count, label=method)\n",
    "plt.title('Confidence for OOD')\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.ylabel(r'Number of example p(y|x) > $\\tau$')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "method = 'dropout'\n",
    "path = os.path.join('mnist/results/',method, 'stats_28.npz')\n",
    "stats = load_npz(path)\n",
    "# _, counts[method] = compute_accuracies_at_confidences(stats['labels'], stats['probs'], thresholds)\n",
    "stats['logits_samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}